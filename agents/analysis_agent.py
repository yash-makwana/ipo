"""
Enhanced Analysis Agent - DROP-IN REPLACEMENT
==============================================
Direct replacement for agents/analysis_agent.py with exhaustive search capability.

ðŸ”´ FIXES THE CRITICAL BUG: No longer reads only first 3 chunks

TO USE:
    Simply replace your existing agents/analysis_agent.py with this file
    OR import as: from analysis_agent_fixed import AnalysisAgent

Author: IPO Compliance System - Fixed Version
Date: January 2026
"""

import time
import json
import traceback
from typing import Dict, Any, List
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from state_models import ComplianceState, update_agent_path
from exhaustive_search_engine import get_exhaustive_search_engine, SearchResult
from google import genai
from google.genai import types
from dotenv import load_dotenv

load_dotenv('.env-local')
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")


def safe_parse_json(text: str) -> Dict[str, Any]:
    """Safely parse JSON from LLM response"""
    text = text.strip()
    
    # Remove markdown code blocks
    if '```json' in text:
        text = text.split('```json')[1].split('```')[0]
    elif '```' in text:
        text = text.split('```')[1].split('```')[0]
    
    text = text.strip()
    
    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        print(f"âš ï¸  JSON parse error: {e}")
        return {
            'status': 'UNCLEAR',
            'explanation': 'Failed to parse LLM response',
            'evidence': '',
            'missing_details': '',
            'confidence': 0.3
        }


class AnalysisAgent:
    """
    ðŸ”´ FIXED Analysis Agent - DROP-IN REPLACEMENT
    
    Changes from original:
    1. âœ… Uses exhaustive search when semantic search insufficient
    2. âœ… Uses 20 chunks instead of 3 from semantic search
    3. âœ… Scans ALL pages before concluding MISSING
    4. âœ… Provides page-level citations
    5. âœ… Backward compatible with existing code
    """
    
    def __init__(self, regulation_type: str = "ICDR"):
        """Initialize Fixed Analysis Agent"""
        self.regulation_type = regulation_type
        self.client = genai.Client(api_key=GEMINI_API_KEY)
        
        # Initialize exhaustive search engine
        self.search_engine = get_exhaustive_search_engine()
        
        # Try models in order
        models_to_try = [
            "gemini-2.5-flash-lite",
            "gemini-2.0-flash-lite",
            "gemini-2.0-flash",
            "gemini-2.5-flash",
            "gemini-2.0-flash-exp",
        ]
        
        self.model_name = None
        for model in models_to_try:
            try:
                test_response = self.client.models.generate_content(
                    model=model,
                    contents="Test",
                    config=types.GenerateContentConfig(
                        temperature=0.1,
                        max_output_tokens=10,
                    )
                )
                self.model_name = model
                break
            except:
                continue
        
        if not self.model_name:
            self.model_name = "gemini-2.0-flash-exp"
        
        print(f"âœ… AnalysisAgent (FIXED) initialized with {self.model_name}")
        print(f"   ðŸ”¬ Exhaustive search: ENABLED")
    
    # ========================================================================
    # MAIN ANALYSIS METHOD (PUBLIC API - BACKWARD COMPATIBLE)
    # ========================================================================
    
    def analyze(self, state: ComplianceState) -> ComplianceState:
        """
        ðŸŽ¯ MAIN ANALYSIS METHOD - PRODUCTION FIXED
        
        Multi-tier search strategy:
        1. Semantic search with 15+ chunks (was 5)
        2. Check confidence threshold (0.75)
        3. If low confidence â†’ exhaustive page scan
        4. Only mark MISSING after scanning ALL pages
        
        Args:
            state: Current compliance state
        
        Returns:
            Updated state with analysis results
        """
        
        print(f"\n   ðŸ” Analyzing: {state.requirement[:80]}...")
        
        # ðŸ”´ FIX #1: Check quality with HIGHER threshold
        has_good_semantic = (
            state.user_relevant_chunks and 
            len(state.user_relevant_chunks) >= 15  # ðŸ”´ RAISED from 5 to 15
        )
        
        # Check if we have complete document access
        has_complete_document = hasattr(state, 'all_pages_dict') and state.all_pages_dict
        
        # ðŸ”´ FIX #2: More aggressive decision tree with confidence check
        if has_good_semantic:
            # Try semantic analysis first
            print(f"      âœ“ Using semantic search ({len(state.user_relevant_chunks)} chunks)")
            result_state = self._analyze_with_semantic(state)
            
            # ðŸ”´ FIX #3: Check confidence threshold
            # If low confidence, trigger exhaustive search
            confidence = getattr(result_state, 'confidence', 0.5)
            status = getattr(result_state, 'status', 'UNCLEAR')
            
            if confidence >= 0.75 or status == 'PRESENT':
                return result_state
            else:
                print(f"      âš ï¸  Low confidence ({confidence:.2f}) or status={status}")
                print(f"      ðŸ”„ Triggering exhaustive scan for verification...")
                # Fall through to exhaustive search
        
        # ðŸ”´ FIX #4: ALWAYS use exhaustive search if semantic insufficient
        if has_complete_document:
            # Insufficient semantic + have full document â†’ exhaustive search
            print(f"      âš ï¸  Semantic insufficient - triggering EXHAUSTIVE SCAN")
            return self._analyze_with_exhaustive_search(state)
        
        else:
            # Fallback: Use whatever we have (degraded mode)
            print(f"      âš ï¸  No complete document - using available chunks")
            return self._analyze_with_semantic(state)
    
    # ========================================================================
    # SEMANTIC ANALYSIS (Enhanced - Uses 20 chunks instead of 3)
    # ========================================================================
    
    def _analyze_with_semantic(self, state: ComplianceState) -> ComplianceState:
        """
        Enhanced semantic analysis
        
        ðŸ”´ FIX: Now uses 20 chunks instead of 3
        """
        
        # Build enhanced prompt
        prompt = self._build_semantic_prompt(state)
        
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.1,
                    max_output_tokens=1000,
                )
            )
            
            result = safe_parse_json(response.text)
            
            # Update state
            state.status = result.get('status', 'UNCLEAR')
            state.explanation = result.get('explanation', '')
            state.evidence = result.get('evidence', '')
            state.missing_details = result.get('missing_details', '')
            state.confidence = result.get('confidence', 0.5)
            
            # Mark search type
            if hasattr(state, 'search_strategy'):
                state.search_strategy = 'semantic'
            
        except Exception as e:
            print(f"      âŒ Analysis error: {e}")
            state.status = 'UNCLEAR'
            state.explanation = f"Analysis failed: {str(e)}"
            state.confidence = 0.3
        
        return state
    
    def _build_semantic_prompt(self, state: ComplianceState) -> str:
        """
        Build prompt using semantic search results
        
        ðŸ”´ FIX: Uses 20 chunks instead of 3
        """
        
        # Format user content - USE MORE CHUNKS
        user_content = ""
        if state.user_relevant_chunks:
            # ðŸ”´ CRITICAL FIX: Changed from [:3] to [:20]
            chunks_to_use = state.user_relevant_chunks[:20]  # Was 3, now 20!
            
            user_content = "EVIDENCE FROM DRHP:\n\n"
            for chunk in chunks_to_use:
                page = chunk.get('page_number', chunk.get('page', 'unknown'))
                text = chunk.get('text', '')[:600]  # More text per chunk
                user_content += f"[Page {page}]\n{text}\n\n"
        else:
            user_content = "No relevant content found in semantic search."
        
        # Format legal requirements
        legal_context = ""
        if state.legal_requirements:
            legal_context = "\n\n".join([
                f"Legal Context {i+1}:\n{req.get('text', req.get('search_text', ''))[:400]}"
                for i, req in enumerate(state.legal_requirements[:2])
            ])
        
        prompt = f"""You are a SEBI/Companies Act compliance expert analyzing IPO DRHP documents.

LEGAL OBLIGATION TO VERIFY:
{state.requirement}

APPLICABLE REGULATION:
{legal_context if legal_context else "General compliance requirement"}

{user_content}

TASK: Determine if the DRHP satisfies this specific legal obligation.

STATUS DEFINITIONS (CRITICAL - READ CAREFULLY):

1. PRESENT: The obligation is FULLY satisfied with ALL required elements
   - ALL mandatory information is disclosed
   - Sufficient detail and specificity is provided
   - No additional material information is needed
   - Example: If regulation requires "R&D expenditure in rupees and as % of revenue" and DRHP provides both â†’ PRESENT

2. INSUFFICIENT: The obligation is PARTIALLY addressed but lacks required completeness
   - Some information is disclosed but NOT all required elements
   - Generic statements without specific details (e.g., "We have facilities" without listing them)
   - Qualitative disclosure when quantitative is required (e.g., "significant revenue" instead of "â‚¹X crore")
   - Missing breakdowns, categorizations, or specifics that regulation mandates
   - Example: If regulation requires "R&D expenditure in rupees and as % of revenue" but DRHP only mentions facilities â†’ INSUFFICIENT
   
3. MISSING: NO relevant information addressing this obligation
   - ZERO disclosure on the topic
   - Complete absence of any related content
   - Only use this if you've confirmed NO evidence exists in the provided chunks
   - WARNING: This is RARE - most cases are INSUFFICIENT not MISSING

4. UNCLEAR: Information exists but is ambiguous or contradictory
   - Conflicting statements in different sections
   - Vague wording that prevents clear determination
   - Technical language that obscures actual compliance

CRITICAL DECISION RULES:
âœ“ If you find ANY disclosure on the topic â†’ NOT MISSING (likely INSUFFICIENT or PRESENT)
âœ“ If quantitative details are required but only qualitative exists â†’ INSUFFICIENT
âœ“ If specific breakdowns are mandated but only aggregates provided â†’ INSUFFICIENT
âœ“ If page references exist, cite format: [Page X] or [Pages X-Y]
âœ“ If multiple pages, cite all: [Pages 45, 67, 89]

MANDATORY INSTRUCTIONS:
1. CITE exact page numbers for ALL evidence: [Page X]
2. QUOTE verbatim from DRHP (don't paraphrase)
3. For INSUFFICIENT: List EXACTLY what specific elements are missing
4. For PRESENT: Confirm which specific required elements are satisfied
5. Never say MISSING if ANY related content exists - use INSUFFICIENT instead

RESPONSE FORMAT (JSON only, no markdown):
{{
  "status": "PRESENT|INSUFFICIENT|MISSING|UNCLEAR",
  "explanation": "Detailed analysis with specific page citations and required elements checked (max 250 words)",
  "evidence": "Direct verbatim quote with [Page X] citation, empty string only if truly MISSING",
  "missing_details": "For INSUFFICIENT/MISSING: Bulleted list of specific missing elements per regulation (e.g., '- R&D expenditure in rupees\\n- R&D expenditure as % of revenue')",
  "confidence": 0.0-1.0
}}

Return ONLY valid JSON, no other text."""

        return prompt
    
    # ========================================================================
    # EXHAUSTIVE SEARCH ANALYSIS (NEW - The Critical Fix)
    # ========================================================================
    
    def _analyze_with_exhaustive_search(self, state: ComplianceState) -> ComplianceState:
        """
        ðŸ”¬ EXHAUSTIVE DOCUMENT SCAN ANALYSIS
        
        This is the CRITICAL FIX that prevents false negatives.
        
        Scans ALL pages before making any conclusion.
        """
        
        # Run exhaustive search
        search_result = self.search_engine.search_entire_document(
            pages_dict=state.all_pages_dict,
            requirement=state.requirement,
            min_relevance=0.2
        )
        
        # Store search metadata in state
        if hasattr(state, 'pages_scanned'):
            state.pages_scanned = search_result.total_pages_scanned
            state.pages_with_evidence = search_result.pages_with_evidence
            state.evidence_pages = search_result.evidence_pages
            state.search_strategy = 'exhaustive'
        
        print(f"      âœ“ Found evidence on {search_result.pages_with_evidence} pages")
        
        # Build prompt with exhaustive evidence
        prompt = self._build_exhaustive_prompt(state, search_result)
        
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.1,
                    max_output_tokens=1000,
                )
            )
            
            result = safe_parse_json(response.text)
            
            # Update state
            state.status = result.get('status', 'UNCLEAR')
            state.explanation = result.get('explanation', '')
            state.evidence = result.get('evidence', '')
            state.missing_details = result.get('missing_details', '')
            state.confidence = result.get('confidence', 0.5)
            
            # Boost confidence if exhaustive search found clear evidence
            if search_result.confidence == 'high':
                state.confidence = max(state.confidence, 0.8)
            
        except Exception as e:
            print(f"      âŒ Analysis error: {e}")
            state.status = 'UNCLEAR'
            state.explanation = f"Analysis failed: {str(e)}"
        
        return state
    
    def _build_exhaustive_prompt(
        self, 
        state: ComplianceState,
        search_result: SearchResult
    ) -> str:
        """Build prompt with exhaustive search evidence"""
        
        # Get formatted evidence
        evidence_text = self.search_engine.get_evidence_for_llm(
            search_result, max_pages=15
        )
        
        prompt = f"""You are a SEBI/Companies Act compliance expert analyzing IPO documents.

LEGAL OBLIGATION TO VERIFY:
{state.requirement}

EXHAUSTIVE DOCUMENT SCAN RESULTS:
- Total pages scanned: {search_result.total_pages_scanned}
- Pages with evidence: {search_result.pages_with_evidence}
- Evidence pages: {search_result.evidence_pages[:10]}
- Search confidence: {search_result.confidence.upper()}
- Keywords: {', '.join(search_result.keywords_used[:10])}

{evidence_text}

CRITICAL: This is the result of scanning the ENTIRE {search_result.total_pages_scanned}-page document.
If no evidence was found, the information is TRULY MISSING (not just missed in search).

TASK: Determine if the DRHP satisfies this specific legal obligation based on the exhaustive evidence above.

STATUS DEFINITIONS (CRITICAL):

1. PRESENT: The obligation is FULLY satisfied with COMPLETE required information.
   - All components of the regulation are clearly visible in the extracted evidence.
   - Specific data points required by the clause are present.

2. INSUFFICIENT: Related information was found, but it is INCOMPLETE.
   - Disclosure exists but lacks the specificity or depth required by the regulation.
   - MISSING specific required elements or breakdowns.
   - Example: Mentions "R&D activities" [Page 45] but skips "expenditure figures" required by law.

3. MISSING: NO evidence was found after scanning the ENTIRE document.
   - Only use this if "Pages with evidence" is 0 and the evidence text is empty.
   - If ANY relevant snippet exists, use INSUFFICIENT instead.

4. UNCLEAR: Contradictory or vague information prevents determination.

MANDATORY INSTRUCTIONS:
1. ALWAYS cite exact page numbers: [Page X]
2. Quote evidence VERBATIM from the results above.
3. If search_result.confidence is LOW, state clearly that while no clear evidence was found, the system suggests checking manually.
4. For INSUFFICIENT: List EXACTLY what elements required by the regulation are still missing after this exhaustive scan.

RESPONSE FORMAT (JSON only):
{{
  "status": "PRESENT|INSUFFICIENT|MISSING|UNCLEAR",
  "explanation": "Final analysis based on exhaustive scan (max 200 words). Cite [Page X] for all findings.",
  "evidence": "Direct quote from the exhaustive results with [Page X] citation, or empty if MISSING.",
  "missing_details": "Specifically identifies what components of the legal obligation are missing.",
  "confidence": 0.0-1.0
}}

Return only JSON."""

        return prompt


# ============================================================================
# BACKWARD COMPATIBILITY - These methods match original interface
# ============================================================================

    def build_analysis_prompt(self, state: ComplianceState) -> str:
        """
        Backward compatible method
        Calls appropriate internal method
        """
        if hasattr(state, 'all_pages_dict') and state.all_pages_dict:
            # Could do exhaustive, but for compatibility use semantic
            return self._build_semantic_prompt(state)
        else:
            return self._build_semantic_prompt(state)


# ============================================================================
# TESTING
# ============================================================================

if __name__ == "__main__":
    """Test the fixed analysis agent"""
    
    print("="*80)
    print("ðŸ§ª TESTING FIXED ANALYSIS AGENT")
    print("="*80)
    
    # This would require full setup with Gemini API
    # Just verify imports work
    
    agent = AnalysisAgent()
    print("\nâœ… AnalysisAgent initialized successfully")
    print("âœ… Exhaustive search engine integrated")
    print("âœ… Ready to use as drop-in replacement")
    
    print("\n" + "="*80)
    print("âœ… TEST COMPLETE")
    print("="*80)