"""
Local PDF Processor - FIXED VERSION
===================================
Extracts ACTUAL PDF page numbers (145, 146, 147...) instead of sequential (1, 2, 3...)

Key Fix:
- Uses pdfplumber's page.page_number OR page labels if available
- Handles PDFs where page numbering doesn't start from 1

Install:
pip install pdfplumber --break-system-packages
"""

import os
import json
from typing import Dict, List, Any
import pdfplumber
from pathlib import Path


class LocalPDFProcessor:
    """
    Local PDF processor using pdfplumber - FIXED VERSION
    """
    
    def __init__(self):
        """Initialize PDF processor"""
        print("âœ… Local PDF Processor initialized (pdfplumber) - FIXED VERSION")
    
    def process_pdf_from_path(self, file_path: str) -> Dict[str, Any]:
        """
        Process PDF from local file path
        
        ğŸ”´ FIX: Now extracts ACTUAL page numbers from PDF
        
        Args:
            file_path: Local path to PDF file
        
        Returns:
            dict: Processed document with text and ACTUAL page mapping
        """
        
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"PDF file not found: {file_path}")
        
        print(f"ğŸ“„ Processing PDF: {file_path}")
        
        pages_data = []
        full_text = ""
        
        try:
            with pdfplumber.open(file_path) as pdf:
                total_pages = len(pdf.pages)
                print(f"   Total pages: {total_pages}")
                
                # ğŸ”´ FIX: Get actual page labels if available
                page_labels = self._extract_page_labels(pdf)
                
                for idx, page in enumerate(pdf.pages):
                    # ğŸ”´ CRITICAL FIX: Use actual page number
                    # Try multiple methods to get the real page number:
                    
                    # Method 1: Use page labels if available
                    if page_labels and idx < len(page_labels):
                        actual_page = page_labels[idx]
                    # Method 2: Use page object's page_number attribute
                    elif hasattr(page, 'page_number'):
                        actual_page = page.page_number
                    # Method 3: Fallback to index + 1
                    else:
                        actual_page = idx + 1
                    
                    # Extract text from page
                    page_text = self._extract_page_text(page, actual_page)
                    
                    # Extract tables if any
                    tables = self._extract_tables(page, actual_page)
                    
                    pages_data.append({
                        'page_number': actual_page,  # ğŸ”´ ACTUAL page number
                        'pdf_index': idx,  # Keep index for reference
                        'text': page_text,
                        'word_count': len(page_text.split()),
                        'has_tables': len(tables) > 0,
                        'table_count': len(tables),
                        'tables': tables
                    })
                    
                    full_text += page_text + "\n\n"
                    
                    if (idx + 1) % 10 == 0:
                        print(f"   Processed {idx + 1}/{total_pages} pages...")
        
        except Exception as e:
            print(f"âŒ Error processing PDF: {e}")
            raise
        
        print(f"âœ… Extracted text from {len(pages_data)} pages")
        
        # ğŸ”´ DEBUG: Show actual page numbers
        if pages_data:
            sample_pages = [p['page_number'] for p in pages_data[:5]]
            print(f"   ğŸ“„ First 5 page numbers: {sample_pages}")
        
        return {
            'full_text': full_text.strip(),
            'pages': pages_data,
            'total_pages': len(pages_data)
        }
    
    def _extract_page_labels(self, pdf) -> List[int]:
        """
        ğŸ”´ NEW METHOD: Extract actual page labels from PDF
        
        Some PDFs have custom page numbering (e.g., starts from 145)
        This tries to extract those labels
        """
        page_labels = []
        
        try:
            # Method 1: Check if PDF has page labels in metadata
            # pdfplumber doesn't directly expose page labels, but we can try
            # to infer from page.page_number
            
            for idx, page in enumerate(pdf.pages):
                if hasattr(page, 'page_number'):
                    page_labels.append(page.page_number)
                else:
                    page_labels.append(idx + 1)
            
            # Check if page numbers are NOT sequential (1, 2, 3...)
            # If they are sequential, the PDF probably doesn't have custom labels
            is_sequential = all(
                page_labels[i] == i + 1 
                for i in range(len(page_labels))
            )
            
            if is_sequential:
                print(f"   â„¹ï¸  PDF uses standard page numbering (1, 2, 3...)")
            else:
                print(f"   âœ… PDF has custom page labels detected")
                print(f"      First page: {page_labels[0]}")
                print(f"      Last page: {page_labels[-1]}")
            
            return page_labels
            
        except Exception as e:
            print(f"   âš ï¸  Could not extract page labels: {e}")
            print(f"   â„¹ï¸  Falling back to sequential numbering")
            return []
    
    def _extract_page_text(self, page, page_num: int) -> str:
        """
        Extract text from a single page with multi-column support
        
        Args:
            page: pdfplumber page object
            page_num: ACTUAL page number (not index)
        
        Returns:
            str: Extracted text
        """
        try:
            # Try layout-preserving extraction first
            text = page.extract_text(layout=True)
            
            if not text or len(text.strip()) < 50:
                # Fallback: basic extraction
                text = page.extract_text()
            
            if not text:
                # Fallback: extract words and join
                words = page.extract_words()
                if words:
                    text = " ".join([w['text'] for w in words])
            
            return text.strip() if text else ""
        
        except Exception as e:
            print(f"   âš ï¸  Warning: Could not extract text from page {page_num}: {e}")
            return ""
    
    def _extract_tables(self, page, page_num: int) -> List[Dict[str, Any]]:
        """
        Extract tables from page
        
        Args:
            page: pdfplumber page object
            page_num: ACTUAL page number (not index)
        
        Returns:
            list: Extracted tables with metadata
        """
        tables = []
        
        try:
            extracted_tables = page.extract_tables()
            
            for idx, table in enumerate(extracted_tables):
                if table and len(table) > 0:
                    # Clean table data
                    cleaned_table = [
                        [cell.strip() if cell else "" for cell in row]
                        for row in table
                    ]
                    
                    # Convert to text representation
                    table_text = self._table_to_text(cleaned_table)
                    
                    tables.append({
                        'table_id': f"page_{page_num}_table_{idx+1}",
                        'rows': len(cleaned_table),
                        'columns': len(cleaned_table[0]) if cleaned_table else 0,
                        'data': cleaned_table,
                        'text': table_text
                    })
        
        except Exception as e:
            print(f"   âš ï¸  Warning: Could not extract tables from page {page_num}: {e}")
        
        return tables
    
    def _table_to_text(self, table: List[List[str]]) -> str:
        """Convert table to readable text format"""
        if not table:
            return ""
        
        lines = []
        for row in table:
            line = " | ".join(row)
            lines.append(line)
        
        return "\n".join(lines)

    def validate_extraction(self, processed_doc: Dict[str, Any]) -> List[str]:
        """
        Validate completeness of extraction
        
        Checks:
        - Sequential page numbers
        - Empty pages
        - Reasonable text length per page
        """
        issues = []
        pages = processed_doc.get('pages', [])
        
        if not pages:
            return ["No pages extracted from document"]
            
        # Check 1: Page Number Range
        page_nums = [p['page_number'] for p in pages]
        page_nums.sort()
        
        if not page_nums:
             return ["No pages found"]

        min_page = min(page_nums)
        max_page = max(page_nums)
        
        print(f"   ğŸ“„ Page range: {min_page} to {max_page}")
        
        # Check for gaps (but be lenient)
        expected_range = list(range(min_page, max_page + 1))
        missing_pages = set(expected_range) - set(page_nums)
        
        if missing_pages:
            if len(missing_pages) < len(page_nums) * 0.1: 
                issues.append(f"Missing pages: {sorted(list(missing_pages))[:10]}")
            else:
                 issues.append(f"Large gap in page numbers detected. Missing {len(missing_pages)} pages.")
            
        # Check 2: Empty/Low Content Pages
        empty_pages = []
        low_content_pages = []
        
        for p in pages:
            text_len = len(p.get('text', '').strip())
            if text_len == 0:
                empty_pages.append(p['page_number'])
            elif text_len < 50:
                low_content_pages.append(p['page_number'])
                
        if empty_pages:
            issues.append(f"Empty pages (potential scan error): {empty_pages[:5]}")
            
        if low_content_pages:
            issues.append(f"Pages with low content (<50 chars): {low_content_pages[:5]}")
            
        return issues


def process_pdf_with_docai(file_path: str) -> Dict[str, Any]:
    """
    Main function - compatible with old GCP interface
    
    Args:
        file_path: Can be local path OR gs:// URI (will convert)
    
    Returns:
        dict: Processed document with text and page mapping
    """
    
    # Handle GCS URIs (convert to local if needed)
    if file_path.startswith('gs://'):
        filename = file_path.split('/')[-1]
        local_path = f"./uploads/{filename}"
        
        if not os.path.exists(local_path):
            raise FileNotFoundError(
                f"GCS URI provided but local file not found: {local_path}\n"
                f"Please download the file first or use local path"
            )
        
        file_path = local_path
    
    # Process with local processor
    processor = LocalPDFProcessor()
    result = processor.process_pdf_from_path(file_path)
    
    # Run validation
    validation_issues = processor.validate_extraction(result)
    if validation_issues:
        print("\nâš ï¸  VALIDATION ISSUES DETECTED:")
        for issue in validation_issues:
            print(f"   - {issue}")
            
    return result


def chunk_document(pages_data: List[Dict], chunk_size: int = 1000, overlap: int = 200) -> List[Dict]:
    """
    Create overlapping chunks from pages while preserving ACTUAL page numbers
    
    ğŸ”´ FIX: Now preserves actual page numbers, not indices
    
    Args:
        pages_data: List of page dictionaries
        chunk_size: Characters per chunk
        overlap: Overlap between chunks
    
    Returns:
        list: Chunks with metadata including ACTUAL page numbers
    """
    chunks = []
    chunk_id = 0
    
    for page in pages_data:
        actual_page_num = page['page_number']  # ğŸ”´ Use actual page number
        text = page['text']
        
        if not text.strip():
            continue
        
        # Split page into chunks if it's long
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunk_text = text[start:end]
            
            if chunk_text.strip():
                chunks.append({
                    'chunk_id': chunk_id,
                    'text': chunk_text,
                    'page_number': actual_page_num,  # ğŸ”´ ACTUAL page number
                    'page': actual_page_num,  # Also add 'page' for compatibility
                    'start_pos': start,
                    'end_pos': end,
                    'has_tables': page.get('has_tables', False)
                })
                chunk_id += 1
            
            start = end - overlap
    
    return chunks


# ============================================================================
# BACKWARD COMPATIBILITY LAYER
# ============================================================================

class DocumentProcessor:
    """
    Document processor class for backward compatibility
    Matches the interface your code expects
    """
    
    def __init__(self):
        self.processor = LocalPDFProcessor()
    
    def process_pdf_with_pages(self, file_path: str) -> List[Dict]:
        """
        Process PDF and return chunks with ACTUAL page numbers
        
        ğŸ”´ FIX: Now returns actual page numbers
        
        Args:
            file_path: Path to PDF file
        
        Returns:
            list: Document chunks with ACTUAL page metadata
        """
        # Process PDF
        result = self.processor.process_pdf_from_path(file_path)
        
        # Create chunks with actual page numbers
        chunks = chunk_document(
            pages_data=result['pages'],
            chunk_size=1000,
            overlap=200
        )
        
        print(f"\nâœ… Created {len(chunks)} chunks")
        if chunks:
            sample_pages = list(set([c['page_number'] for c in chunks[:10]]))
            print(f"   ğŸ“„ Sample page numbers: {sorted(sample_pages)}")
        
        return chunks
    
    def extract_text_with_pages(self, file_path: str) -> Dict[str, Any]:
        """
        Extract text with page-level granularity
        
        Args:
            file_path: Path to PDF file
        
        Returns:
            dict: Full result with pages
        """
        return self.processor.process_pdf_from_path(file_path)


# ============================================================================
# TESTING
# ============================================================================

if __name__ == "__main__":
    """Test the FIXED local PDF processor"""
    
    print("="*80)
    print("ğŸ§ª TESTING FIXED LOCAL PDF PROCESSOR")
    print("="*80)
    
    # Test with your actual PDF
    test_file = "/mnt/user-data/uploads/Business_chapters_Queries_17_12_25_.pdf"
    
    if not os.path.exists(test_file):
        print(f"\nâš ï¸  Test file not found: {test_file}")
        print("   Using fallback test file")
        test_file = "./test.pdf"
    
    if os.path.exists(test_file):
        # Test 1: Full processing
        print("\n[TEST 1] Full PDF Processing with ACTUAL Page Numbers")
        print("-"*80)
        
        result = process_pdf_with_docai(test_file)
        print(f"âœ… Processed {result['total_pages']} pages")
        
        if result['pages']:
            # Show page number range
            page_nums = [p['page_number'] for p in result['pages']]
            print(f"\nğŸ“„ Page number range: {min(page_nums)} to {max(page_nums)}")
            print(f"   First 10 pages: {page_nums[:10]}")
            
            print(f"\nFirst page preview:")
            first_page = result['pages'][0]
            print(f"  Page number: {first_page['page_number']}")
            print(f"  Text: {first_page['text'][:200]}...")
        
        # Test 2: Chunking with actual pages
        print("\n[TEST 2] Document Chunking with ACTUAL Page Numbers")
        print("-"*80)
        
        chunks = chunk_document(result['pages'], chunk_size=500, overlap=100)
        print(f"âœ… Created {len(chunks)} chunks")
        
        if chunks:
            unique_pages = sorted(list(set([c['page_number'] for c in chunks])))
            print(f"\n  Unique pages in chunks: {len(unique_pages)}")
            print(f"  Page number range: {unique_pages[0]} to {unique_pages[-1]}")
            print(f"\nFirst chunk:")
            print(f"  Page: {chunks[0]['page_number']}")
            print(f"  Text: {chunks[0]['text'][:150]}...")
        
        print("\n" + "="*80)
        print("âœ… FIXED PDF PROCESSOR TEST COMPLETE")
        print("="*80)
        
        # ğŸ”´ CRITICAL VALIDATION
        if result['pages']:
            first_page_num = result['pages'][0]['page_number']
            if first_page_num == 1:
                print("\nâš ï¸  WARNING: Page numbers start from 1")
                print("   This PDF may use standard numbering")
            else:
                print(f"\nâœ… SUCCESS: Page numbers start from {first_page_num}")
                print("   Actual page labels detected correctly!")
    else:
        print(f"âŒ No test file found")